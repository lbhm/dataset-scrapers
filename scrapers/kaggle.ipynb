{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Datasets Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import kaggle\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import pickle\n",
    "\n",
    "kaggle.api.authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of all Kaggle Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the tables `Datasets`, `DatasetVersions`, and `Users` from the [Meta Kaggle](https://www.kaggle.com/datasets/kaggle/meta-kaggle) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 312769 entries, 0 to 312768\n",
      "Data columns (total 4 columns):\n",
      " #   Column                   Non-Null Count   Dtype\n",
      "---  ------                   --------------   -----\n",
      " 0   DatasetId                312769 non-null  int64\n",
      " 1   CreatorUserId            312769 non-null  int64\n",
      " 2   OwnerUserId              310449 non-null  Int64\n",
      " 3   CurrentDatasetVersionId  312664 non-null  Int64\n",
      "dtypes: Int64(2), int64(2)\n",
      "memory usage: 10.1 MB\n"
     ]
    }
   ],
   "source": [
    "username_slug = pd.read_csv(\"../data/Datasets.csv\", dtype={\"CurrentDatasetVersionId\": \"Int64\", \"OwnerUserId\": \"Int64\"})\n",
    "username_slug = username_slug[[\"Id\", \"CreatorUserId\", \"OwnerUserId\", \"CurrentDatasetVersionId\"]]\n",
    "username_slug = username_slug.rename(columns={\"Id\": \"DatasetId\"})\n",
    "username_slug.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1054141 entries, 0 to 1054140\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count    Dtype  \n",
      "---  ------            --------------    -----  \n",
      " 0   DatasetVersionId  1054141 non-null  int64  \n",
      " 1   CreatorUserId     1054141 non-null  int64  \n",
      " 2   VersionNumber     980122 non-null   float64\n",
      " 3   Slug              1054141 non-null  object \n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 32.2+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset_versions = pd.read_csv(\"../data/DatasetVersions.csv\")\n",
    "dataset_versions = dataset_versions[\n",
    "    [\"Id\", \"CreatorUserId\", \"VersionNumber\", \"Slug\"]\n",
    "]\n",
    "dataset_versions = dataset_versions.rename(columns={\"Id\": \"DatasetVersionId\"})\n",
    "dataset_versions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17553389 entries, 0 to 17553388\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Dtype \n",
      "---  ------    ----- \n",
      " 0   UserId    int64 \n",
      " 1   UserName  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 267.8+ MB\n"
     ]
    }
   ],
   "source": [
    "users = pd.read_csv(\"../data/Users.csv\")\n",
    "users = users[[\"Id\", \"UserName\"]]\n",
    "users = users.rename(columns={\"Id\": \"UserId\"})\n",
    "users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 301969 entries, 4 to 312768\n",
      "Data columns (total 10 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   DatasetId                301969 non-null  int64  \n",
      " 1   CreatorUserId_x          301969 non-null  int64  \n",
      " 2   OwnerUserId              301969 non-null  Int64  \n",
      " 3   CurrentDatasetVersionId  301969 non-null  Int64  \n",
      " 4   DatasetVersionId         301969 non-null  float64\n",
      " 5   CreatorUserId_y          301969 non-null  float64\n",
      " 6   VersionNumber            301783 non-null  float64\n",
      " 7   Slug                     301969 non-null  object \n",
      " 8   UserId                   301969 non-null  float64\n",
      " 9   UserName                 301969 non-null  object \n",
      "dtypes: Int64(2), float64(4), int64(2), object(2)\n",
      "memory usage: 25.9+ MB\n"
     ]
    }
   ],
   "source": [
    "merged = username_slug.merge(\n",
    "    dataset_versions,\n",
    "    how=\"left\",\n",
    "    left_on=[\"CurrentDatasetVersionId\"],\n",
    "    right_on=[\"DatasetVersionId\"],\n",
    ").merge(\n",
    "    users, \n",
    "    how=\"left\",\n",
    "    left_on=\"OwnerUserId\",\n",
    "    right_on=\"UserId\",\n",
    ")\n",
    "merged.dropna(subset=[\"UserName\", \"Slug\"], inplace=True)\n",
    "merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[[\"UserName\", \"Slug\"]].to_csv(\"../data/username_slug.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather dataset metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "username_slug = pd.read_csv(\"../data/username_slug.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = []\n",
    "errors = []\n",
    "for user in tqdm.tqdm(username_slug[\"UserName\"].unique()):\n",
    "    try:\n",
    "        page = 1\n",
    "        while True:\n",
    "            results = kaggle.api.dataset_list(\n",
    "                sort_by=\"hottest\",\n",
    "                file_type=\"csv\",\n",
    "                license_name=\"all\",\n",
    "                user=user,\n",
    "                page=page,\n",
    "            )\n",
    "            if results:\n",
    "                metadata.extend(results)\n",
    "            if len(results) < 10:\n",
    "                break\n",
    "\n",
    "            page += 1\n",
    "            if page > 500:\n",
    "                print(\n",
    "                    f\"User {user} has more than 10000 datasets. The API won't show all of them.\"\n",
    "                )\n",
    "\n",
    "            time.sleep(0.01)\n",
    "    except Exception as e:\n",
    "        errors.append((user, e))\n",
    "\n",
    "with open(\"../data/metadata.pkl\", \"wb\") as file:\n",
    "    pickle.dump(metadata, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle.api.dataset_download_files('sudalairajkumar/novel-corona-virus-2019-dataset', path='./data', unzip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "daatset_list\n",
    "dataset_metadata\n",
    "dataset_status\n",
    "dataset_list_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = []\n",
    "page = 1\n",
    "while True:\n",
    "    results = kaggle.api.dataset_list(\n",
    "        sort_by=\"hottest\",\n",
    "        file_type=\"csv\",\n",
    "        license_name=\"all\",\n",
    "        tag_ids=\"\",\n",
    "        search=\"\",\n",
    "        page=page,\n",
    "    )\n",
    "    page += 1\n",
    "\n",
    "    if len(results) == 0:\n",
    "        break\n",
    "    else:\n",
    "        metadata.extend(results)\n",
    "\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9976"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[hashidoyuto/presidio-analyzer,\n",
       " ady5215758/model80,\n",
       " thefc17/epl-results-19932018,\n",
       " yasserh/air-passengers-forecast-dataset,\n",
       " miguelrcborges/league-of-legends-patch-14-1-soloq-teamcomp-30k,\n",
       " humananalog/deepfakes-inference-demo,\n",
       " vinayakshanawad/heart-rate-prediction-to-monitor-stress-level,\n",
       " raniajaberi/custom-data,\n",
       " debanga/facial-expression-recognition-challenge,\n",
       " jonathanimmanuel/barcode-and-qr,\n",
       " mahoora00135/flights,\n",
       " esensing/sits-bundle,\n",
       " japandata509/shinkansen-stations-in-japan,\n",
       " catalystcooperative/pudl-project,\n",
       " tombutton/weather-data-edexcel-large-data-set,\n",
       " arnabchaki/tripadvisor-reviews-2023,\n",
       " asaniczka/san-francisco-police-stop-data-2018-2023,\n",
       " zusmani/pakistans-job-market,\n",
       " sunethjayawardana/google-data-analyst-case-study-cyclist,\n",
       " noordeen/employee-attrition]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle.api.dataset_list(\n",
    "    tag_ids=\"\",\n",
    "    search=\"\",\n",
    "    page=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subtitleNullable': 'Day level information on covid-19 affected cases',\n",
       " 'creatorNameNullable': 'SRK',\n",
       " 'creatorUrlNullable': 'sudalairajkumar',\n",
       " 'totalBytesNullable': 8928752,\n",
       " 'urlNullable': 'https://www.kaggle.com/datasets/sudalairajkumar/novel-corona-virus-2019-dataset',\n",
       " 'licenseNameNullable': 'Data files © Original Authors',\n",
       " 'descriptionNullable': None,\n",
       " 'ownerNameNullable': 'SRK',\n",
       " 'ownerRefNullable': 'sudalairajkumar',\n",
       " 'titleNullable': 'Novel Corona Virus 2019 Dataset',\n",
       " 'currentVersionNumberNullable': 151,\n",
       " 'usabilityRatingNullable': 0.9705882,\n",
       " 'id': 494724,\n",
       " 'ref': 'sudalairajkumar/novel-corona-virus-2019-dataset',\n",
       " 'subtitle': 'Day level information on covid-19 affected cases',\n",
       " 'hasSubtitle': True,\n",
       " 'creatorName': 'SRK',\n",
       " 'hasCreatorName': True,\n",
       " 'creatorUrl': 'sudalairajkumar',\n",
       " 'hasCreatorUrl': True,\n",
       " 'totalBytes': 8928752,\n",
       " 'hasTotalBytes': True,\n",
       " 'url': 'https://www.kaggle.com/datasets/sudalairajkumar/novel-corona-virus-2019-dataset',\n",
       " 'hasUrl': True,\n",
       " 'lastUpdated': datetime.datetime(2021, 6, 24, 4, 27, 25),\n",
       " 'downloadCount': 429106,\n",
       " 'isPrivate': False,\n",
       " 'isFeatured': False,\n",
       " 'licenseName': 'Data files © Original Authors',\n",
       " 'hasLicenseName': True,\n",
       " 'description': '',\n",
       " 'hasDescription': False,\n",
       " 'ownerName': 'SRK',\n",
       " 'hasOwnerName': True,\n",
       " 'ownerRef': 'sudalairajkumar',\n",
       " 'hasOwnerRef': True,\n",
       " 'kernelCount': 1691,\n",
       " 'title': 'Novel Corona Virus 2019 Dataset',\n",
       " 'hasTitle': True,\n",
       " 'topicCount': 0,\n",
       " 'viewCount': 2464577,\n",
       " 'voteCount': 6125,\n",
       " 'currentVersionNumber': 151,\n",
       " 'hasCurrentVersionNumber': True,\n",
       " 'usabilityRating': 0.9705882,\n",
       " 'hasUsabilityRating': True,\n",
       " 'tags': [public health, health, law, health conditions, covid19],\n",
       " 'files': [],\n",
       " 'versions': [],\n",
       " 'size': '9MB'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle.api.dataset_list(\n",
    "    sort_by=\"hottest\",\n",
    "    file_type=\"csv\",\n",
    "    license_name=\"all\",\n",
    "    tag_ids=\"\",\n",
    "    search=\"novel-corona-virus-2019-dataset\",\n",
    "    page=1,\n",
    ")[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./test/dataset-metadata.json'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle.api.dataset_metadata('sudalairajkumar/novel-corona-virus-2019-dataset', \"./test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle.api.dataset_download_files('marquis03/flower-classification', path='./data', unzip=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
